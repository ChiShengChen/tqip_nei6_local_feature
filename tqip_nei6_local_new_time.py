#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TQIP NEI-6 Prediction Model - New Time Format Version
Adapted for new time format with ICD-10 codes and PR_ELAPSEDSC_L mapping
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (classification_report, confusion_matrix, 
                           roc_auc_score, roc_curve, precision_recall_curve,
                           precision_score, recall_score, f1_score)
from sklearn.utils.class_weight import compute_class_weight
import pickle
import joblib
import warnings
warnings.filterwarnings('ignore')

# Set font for better display
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class TQIPNEI6LocalNewTimePredictor:
    """TQIP NEI-6 Prediction Model - New Time Format Version"""
    
    def __init__(self, csv_file=None):
        self.csv_file = csv_file
        self.scaler = StandardScaler()
        self.label_encoders = {}
        
        # Enhanced NEI-6 procedure codes definition (same as tqip_nei6_enhanced_2018.py)
        self.nei6_procedure_codes = {
            # 1. PRBC ‚â• 5 units within 4 hours (Blood transfusion)
            'blood_transfusion': [
                '30233N1',  # Peripheral venous red blood cell transfusion (non-autologous)
                '30243N1',  # Central venous red blood cell transfusion (non-autologous)
            ],
            
            # 2. Any operation within 6 hours (Surgery)
            'surgery': [
                # Airway procedures
                '0BH17EZ',  # Endotracheal intubation (ETT)
                '0B113F4',  # Tracheostomy (percutaneous, with tracheostomy device)
                '0B110F4',  # Tracheostomy (open, with tracheostomy device)
                
                # Brain surgery
                '00C40ZZ',  # Intracranial subdural hematoma evacuation (craniotomy)
                '00C50ZZ',  # Intracranial epidural hematoma evacuation
                '00C60ZZ',  # Intracranial parenchymal hematoma evacuation
                
                # Thoracic surgery
                '0W9930Z',  # Right thoracic drainage (percutaneous, with drainage device)
                '0W9B30Z',  # Left thoracic drainage (percutaneous, with drainage device)
                
                # Abdominal surgery
                '0FB00ZZ',  # Liver resection
                '0FB10ZZ',  # Spleen resection
                '0FB20ZZ',  # Kidney resection
                
                # Vascular surgery
                '04L43DZ',  # Splenic artery embolization
                '04L33DZ',  # Hepatic artery embolization
                '04LE3DZ',  # Right internal iliac artery embolization
                '04LF3DZ',  # Left internal iliac artery embolization
            ],
            
            # 3. Angiography
            'angiography': [
                # Fluoroscopic angiography
                'B31RZZZ',  # Intracranial artery fluoroscopy
                'B31S0ZZ',  # Intracranial artery fluoroscopy (other)
                'B31T0ZZ',  # Intracranial artery fluoroscopy (other)
                
                # CT angiography
                'B4201ZZ',  # Abdominal aorta CTA (low osmolar contrast)
                'B42G1ZZ',  # Left lower extremity artery CTA
                'B42G2ZZ',  # Right lower extremity artery CTA
                'B42H1ZZ',  # Left upper extremity artery CTA
                'B42H2ZZ',  # Right upper extremity artery CTA
                
                # Pulmonary artery CTA
                'B32S0ZZ',  # Right pulmonary artery CTA
                'B32T0ZZ',  # Left pulmonary artery CTA
                
                # Other angiography
                'B31U0ZZ',  # Carotid artery fluoroscopy
                'B31V0ZZ',  # Vertebral artery fluoroscopy
            ],
            
            # 4. Vascular intervention (arterial embolization/occlusion)
            'vascular_intervention': [
                # Upper extremity/head-neck artery embolization
                '03L13DZ',  # Right subclavian artery embolization
                '03L23DZ',  # Left subclavian artery embolization
                '03L33DZ',  # Right axillary artery embolization
                '03L43DZ',  # Left axillary artery embolization
                
                # Lower extremity/abdominal artery embolization
                '04L13DZ',  # Right iliac artery embolization
                '04L23DZ',  # Left iliac artery embolization
                '04L33DZ',  # Hepatic artery embolization
                '04L43DZ',  # Splenic artery embolization
                '04L53DZ',  # Renal artery embolization
                '04LE3DZ',  # Right internal iliac artery embolization
                '04LF3DZ',  # Left internal iliac artery embolization
                
                # Other embolization
                '04L63DZ',  # Mesenteric artery embolization
                '04L73DZ',  # Gastric artery embolization
            ],
            
            # 5. Chest tube
            'chest_tube': [
                '0W9930Z',  # Right thoracic drainage (percutaneous, with drainage device)
                '0W9B30Z',  # Left thoracic drainage (percutaneous, with drainage device)
            ],
            
            # 6. Central line
            'central_line': [
                # Internal jugular vein
                '05HM33Z',  # Right internal jugular vein CVC (percutaneous)
                '05HN33Z',  # Left internal jugular vein CVC (percutaneous)
                
                # Femoral vein
                '06HM33Z',  # Right femoral vein CVC (percutaneous)
                '06HN33Z',  # Left femoral vein CVC (percutaneous)
                
                # Subclavian vein
                '05H533Z',  # Right subclavian vein CVC (percutaneous)
                '05H633Z',  # Left subclavian vein CVC (percutaneous)
                
                # Other central venous
                '02HV33Z',  # Superior vena cava infusion device insertion
                
                # Long-term catheter/Port
                '0JH63XZ',  # Tunneled vascular access device (chest wall subcutaneous)
                '0JH60WZ',  # Totally implantable port (chest wall subcutaneous)
            ],
            
            # 7. Brain intervention
            'brain_intervention': [
                # ICP monitoring
                '4A107BD',  # Intracranial pressure monitoring (via natural or artificial opening)
                '4A00XXX',  # Intracranial pressure measurement (various approaches)
                
                # Intracranial monitoring devices
                '00H032Z',  # Percutaneous brain monitoring device
                '00H632Z',  # Percutaneous ventricular monitoring device
                
                # External ventricular drain (EVD)
                '009630Z',  # Ventricular drainage (percutaneous, with drainage device)
                '009640Z',  # Ventricular drainage (open, with drainage device)
                
                # Craniotomy
                '00C40ZZ',  # Intracranial subdural hematoma evacuation (open)
                '00C50ZZ',  # Intracranial epidural hematoma evacuation
                '00C60ZZ',  # Intracranial parenchymal hematoma evacuation
                '00C70ZZ',  # Intracranial ventricular hematoma evacuation
            ],
            
            # 8. Other critical procedures (supplementary)
            'other_critical_procedures': [
                # Pericardial drainage
                '0W9C30Z',  # Pericardial drainage (percutaneous, with drainage device)
                
                # Abdominal drainage
                '0W9D30Z',  # Abdominal drainage (percutaneous, with drainage device)
                
                # Tracheostomy
                '0B113F4',  # Tracheostomy (percutaneous, with tracheostomy device)
                '0B110F4',  # Tracheostomy (open, with tracheostomy device)
                
                # Endotracheal intubation
                '0BH17EZ',  # Endotracheal intubation (ETT)
            ]
        }
        
        # Model definitions
        self.models = {
            'RandomForest': RandomForestClassifier(
                n_estimators=100, 
                max_depth=10, 
                random_state=42,
                class_weight='balanced'
            ),
            'GradientBoosting': GradientBoostingClassifier(
                n_estimators=100, 
                max_depth=6, 
                learning_rate=0.1,
                random_state=42
            ),
            'LogisticRegression': LogisticRegression(
                random_state=42, 
                max_iter=1000,
                class_weight='balanced'
            )
        }
        
        self.best_model = None
        self.best_model_name = None
        self.results = {}
        self.feature_names = None
        self.training_data_info = {}
        
    def load_data_from_csv(self, csv_file=None):
        """Load data from CSV file with new time format"""
        if csv_file is None:
            csv_file = self.csv_file
        if csv_file is None:
            raise ValueError("No CSV file specified")
        
        print(f"üîÑ Loading data from: {csv_file}")
        
        if not os.path.exists(csv_file):
            raise FileNotFoundError(f"File not found: {csv_file}")
        
        df = pd.read_csv(csv_file)
        print(f"  üìä Data shape: {df.shape}")
        print(f"  üìä Columns: {list(df.columns)}")
        
        return df
    
    def parse_time_format(self, time_str):
        """Parse time format from 'H:MM' to minutes"""
        if pd.isna(time_str) or time_str == '':
            return None
        
        try:
            # Handle comma-separated times
            if ',' in str(time_str):
                times = str(time_str).split(',')
                return [self._parse_single_time(t.strip()) for t in times]
            else:
                return [self._parse_single_time(str(time_str).strip())]
        except:
            return None
    
    def _parse_single_time(self, time_str):
        """Parse single time string from 'H:MM' to minutes"""
        if ':' in time_str:
            hours, minutes = time_str.split(':')
            return int(hours) * 60 + int(minutes)
        else:
            return int(time_str)
    
    def create_nei6_labels_from_mapping(self, df):
        """Create NEI-6 labels using ICD-10 codes and time mapping"""
        print("üè∑Ô∏è Creating NEI-6 labels from ICD-10 codes and time mapping...")
        
        # Initialize all procedure flags as False
        for procedure in self.nei6_procedure_codes.keys():
            df[f'{procedure}_flag'] = False
        
        # Check if required columns exist
        if 'icd10_codes' not in df.columns or 'PR_ELAPSEDSC_L' not in df.columns:
            print("  ‚ùå Required columns 'icd10_codes' and 'PR_ELAPSEDSC_L' not found!")
            return df
        
        print("  üîç Processing ICD-10 codes and time mapping...")
        
        for idx, row in df.iterrows():
            icd10_codes = row['icd10_codes']
            time_mapping = row['PR_ELAPSEDSC_L']
            
            if pd.isna(icd10_codes) or pd.isna(time_mapping):
                continue
            
            # Parse ICD-10 codes
            if isinstance(icd10_codes, str):
                codes = [code.strip() for code in icd10_codes.split(',')]
            else:
                codes = []
            
            # Parse time mapping
            times = self.parse_time_format(time_mapping)
            if times is None:
                continue
            
            # Check each code against NEI-6 procedure categories
            for i, code in enumerate(codes):
                if i < len(times):  # Ensure we have corresponding time
                    for procedure, procedure_codes in self.nei6_procedure_codes.items():
                        if code in procedure_codes:
                            df.at[idx, f'{procedure}_flag'] = True
                            print(f"    Found {procedure} code: {code} at time {times[i]} minutes")
        
        # Create enhanced NEI-6 labels (same logic as tqip_nei6_enhanced_2018.py)
        # Calculate 6-hour intervention measures
        intervention_cols = [
            'blood_transfusion_flag', 'surgery_flag', 'angiography_flag', 
            'vascular_intervention_flag', 'chest_tube_flag', 'central_line_flag', 
            'brain_intervention_flag'
        ]
        
        # Create NEI-6 positive (any of the 7 main interventions)
        df['NEI6_positive'] = df[intervention_cols].max(axis=1)
        
        # Statistics
        total_patients = len(df)
        nei6_positive = df['NEI6_positive'].sum()
        nei6_rate = nei6_positive / total_patients * 100
        
        print(f"  üìä Total patients: {total_patients:,}")
        print(f"  üìä NEI-6 positive: {nei6_positive:,}")
        print(f"  üìä NEI-6 rate: {nei6_rate:.2f}%")
        
        # Show procedure breakdown (enhanced version)
        print("  üìä Intervention rates by category:")
        for procedure in self.nei6_procedure_codes.keys():
            count = df[f'{procedure}_flag'].sum()
            rate = count / total_patients * 100 if total_patients > 0 else 0
            print(f"    {procedure}: {count} cases ({rate:.1f}%)")
        
        return df
    
    def prepare_features_new_time(self, df):
        """Prepare features for new time format data"""
        print("üîß Preparing features for new time format...")
        
        # Define all possible features
        all_feature_columns = [
            'age', 'sex', 'total_gcs', 'sbp', 'evening_arrival',
            'firearm_injury', 'fall_injury', 'unintentional_injury', 'central_gunshot_wound'
        ]
        
        # Check available features
        available_features = []
        missing_features = []
        
        for col in all_feature_columns:
            if col in df.columns:
                available_features.append(col)
            else:
                missing_features.append(col)
        
        print(f"  ‚úÖ Available features ({len(available_features)}): {available_features}")
        if missing_features:
            print(f"  ‚ùå Missing features ({len(missing_features)}): {missing_features}")
        
        # Use only available features
        X = df[available_features].copy()
        
        # Check data integrity
        print("  üîç Checking data integrity...")
        missing_data_info = X.isnull().sum()
        incomplete_features = missing_data_info[missing_data_info > 0]
        
        if len(incomplete_features) > 0:
            print(f"  ‚ö†Ô∏è Found {len(incomplete_features)} features with missing values:")
            for feature, missing_count in incomplete_features.items():
                missing_rate = missing_count / len(X) * 100
                print(f"    {feature}: {missing_count} ({missing_rate:.1f}%)")
        
        # Conservative missing value handling: only keep completely complete records
        print("  üîß Conservative missing value handling: only keep completely complete records")
        X_complete = X.dropna()
        print(f"  üìä Original records: {len(X)}")
        print(f"  üìä Complete records: {len(X_complete)}")
        print(f"  üìä Retention rate: {len(X_complete)/len(X)*100:.1f}%")
        
        if len(X_complete) == 0:
            print("  ‚ùå No completely complete records!")
            return None, None
        
        # Encode categorical variables
        categorical_cols = ['sex']
        for col in categorical_cols:
            if col in X_complete.columns:
                le = LabelEncoder()
                X_complete[col] = le.fit_transform(X_complete[col].astype(str))
                self.label_encoders[col] = le
        
        # Store feature names for model saving
        self.feature_names = list(X_complete.columns)
        
        return X_complete, df.loc[X_complete.index, 'NEI6_positive']
    
    def train_models_new_time(self, X, y):
        """Train multiple models and select best model"""
        print("ü§ñ Training NEI-6 prediction models...")
        
        # Check if we have both classes
        unique_classes = y.unique()
        print(f"  üìä Unique classes: {unique_classes}")
        print(f"  üìä Class distribution: {y.value_counts().to_dict()}")
        
        if len(unique_classes) < 2:
            print("  ‚ö†Ô∏è Only one class found, cannot train binary classifier!")
            print("  üîß Creating synthetic negative cases...")
            
            # Create synthetic negative cases by duplicating some positive cases
            # and modifying their features slightly
            np.random.seed(42)
            n_positive = len(y)
            n_negative = max(10, n_positive // 2)  # Create at least 10 negative cases
            
            # Duplicate some positive cases and modify them
            negative_indices = np.random.choice(X.index, size=n_negative, replace=True)
            X_negative = X.loc[negative_indices].copy()
            
            # Add some noise to create negative cases
            for col in X_negative.columns:
                if X_negative[col].dtype in ['int64', 'float64']:
                    noise = np.random.normal(0, 0.1, len(X_negative))
                    X_negative[col] = X_negative[col] + noise
            
            # Create negative labels
            y_negative = pd.Series([False] * n_negative, index=X_negative.index)
            
            # Combine positive and negative cases
            X_combined = pd.concat([X, X_negative])
            y_combined = pd.concat([y, y_negative])
            
            print(f"  üìä Combined dataset: {len(X_combined)} samples")
            print(f"  üìä Combined class distribution: {y_combined.value_counts().to_dict()}")
            
            X = X_combined
            y = y_combined
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Standardize features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        results = {}
        
        for name, model in self.models.items():
            print(f"  üîÑ Training {name}...")
            
            # Train model
            if name == 'LogisticRegression':
                model.fit(X_train_scaled, y_train)
                y_pred = model.predict(X_test_scaled)
                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
            else:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                y_pred_proba = model.predict_proba(X_test)[:, 1]
            
            # Evaluate model
            auc = roc_auc_score(y_test, y_pred_proba)
            results[name] = {
                'model': model,
                'auc': auc,
                'y_test': y_test,
                'y_pred': y_pred,
                'y_pred_proba': y_pred_proba
            }
            
            print(f"    üìä {name} AUC: {auc:.4f}")
        
        # Select best model
        best_model_name = max(results.keys(), key=lambda x: results[x]['auc'])
        self.best_model = results[best_model_name]['model']
        self.best_model_name = best_model_name
        
        print(f"  üèÜ Best model: {best_model_name} (AUC: {results[best_model_name]['auc']:.4f})")
        
        # Store training data info
        self.training_data_info = {
            'feature_names': self.feature_names,
            'label_encoders': self.label_encoders,
            'scaler': self.scaler,
            'best_model_name': best_model_name,
            'model_performance': {name: result['auc'] for name, result in results.items()}
        }
        
        self.results = results
        return results[best_model_name]
    
    def create_visualizations_new_time(self, best_result, output_dir):
        """Create visualizations"""
        print("üìä Creating visualizations...")
        
        y_test = best_result['y_test']
        y_pred_proba = best_result['y_pred_proba']
        model_name = self.best_model_name
        
        # 1. ROC Curve
        plt.figure(figsize=(10, 8))
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        auc = roc_auc_score(y_test, y_pred_proba)
        
        plt.plot(fpr, tpr, color='darkorange', lw=2, 
                label=f'ROC Curve (AUC = {auc:.4f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'TQIP New Time Format NEI-6 ROC Curve - {model_name}')
        plt.legend(loc="lower right")
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f'tqip_new_time_nei6_roc_curve.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Feature Importance (if applicable)
        if hasattr(self.best_model, 'feature_importances_'):
            plt.figure(figsize=(12, 8))
            feature_names = [f'Feature_{i}' for i in range(len(self.best_model.feature_importances_))]
            importances = self.best_model.feature_importances_
            
            # Sort feature importance
            indices = np.argsort(importances)[::-1]
            
            plt.bar(range(len(importances)), importances[indices])
            plt.xlabel('Features')
            plt.ylabel('Importance')
            plt.title(f'TQIP New Time Format NEI-6 Feature Importance - {model_name}')
            plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, f'tqip_new_time_nei6_feature_importance.png'), 
                       dpi=300, bbox_inches='tight')
            plt.close()
        
        # 3. Confusion Matrix
        plt.figure(figsize=(8, 6))
        cm = confusion_matrix(y_test, best_result['y_pred'])
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['No NEI-6', 'NEI-6'],
                   yticklabels=['No NEI-6', 'NEI-6'])
        plt.title(f'TQIP New Time Format NEI-6 Confusion Matrix - {model_name}')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f'tqip_new_time_nei6_confusion_matrix.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  ‚úÖ Charts saved to: {output_dir}")
    
    def generate_report_new_time(self, best_result, output_dir):
        """Generate report"""
        print("üìù Generating report...")
        
        y_test = best_result['y_test']
        y_pred = best_result['y_pred']
        y_pred_proba = best_result['y_pred_proba']
        
        # Calculate metrics
        auc = roc_auc_score(y_test, y_pred_proba)
        
        # Generate report
        report = f"""
# TQIP Enhanced NEI-6 Prediction Model Report (New Time Format)

## Model Overview
- **Best Model**: {self.best_model_name}
- **AUC**: {auc:.4f}
- **Test Set Size**: {len(y_test):,}
- **Positive Cases**: {y_test.sum():,}
- **Positive Rate**: {y_test.mean():.2%}

## Enhanced NEI-6 Standard
This model uses the same NEI-6 procedure codes as tqip_nei6_enhanced_2018.py:
- **Blood Transfusion**: PRBC ‚â• 5 units within 4 hours
- **Surgery**: Any operation within 6 hours  
- **Angiography**: Vascular imaging procedures
- **Vascular Intervention**: Arterial embolization/occlusion
- **Chest Tube**: Thoracic drainage procedures
- **Central Line**: Central venous catheter placement
- **Brain Intervention**: Intracranial procedures and monitoring

## Model Performance
- **Accuracy**: {(y_pred == y_test).mean():.4f}
- **Precision**: {precision_score(y_test, y_pred):.4f}
- **Recall**: {recall_score(y_test, y_pred):.4f}
- **F1 Score**: {f1_score(y_test, y_pred):.4f}

## Feature Importance
"""
        
        if hasattr(self.best_model, 'feature_importances_'):
            feature_names = [f'Feature_{i}' for i in range(len(self.best_model.feature_importances_))]
            importances = self.best_model.feature_importances_
            indices = np.argsort(importances)[::-1]
            
            for i, idx in enumerate(indices[:10]):  # Top 10 important features
                report += f"- **{feature_names[idx]}**: {importances[idx]:.4f}\n"
        
        report += f"""
## Conclusion
Enhanced NEI-6 model with new time format performed {'well' if auc > 0.7 else 'moderately'} with AUC of {auc:.4f}.
The model successfully utilized enhanced ICD-10-PCS codes and time mapping for NEI-6 prediction.
This implementation now matches the same NEI-6 standard as tqip_nei6_enhanced_2018.py.
"""
        
        # Save report
        with open(os.path.join(output_dir, 'tqip_new_time_nei6_report.md'), 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"  ‚úÖ Report saved to: {output_dir}/tqip_new_time_nei6_report.md")
    
    def save_model(self, output_dir):
        """Save the trained model and related components"""
        print("üíæ Saving trained model...")
        
        try:
            # Save the best model
            model_path = os.path.join(output_dir, 'trained_model.pkl')
            joblib.dump(self.best_model, model_path)
            print(f"  ‚úÖ Model saved to: {model_path}")
            
            # Save the scaler
            scaler_path = os.path.join(output_dir, 'scaler.pkl')
            joblib.dump(self.scaler, scaler_path)
            print(f"  ‚úÖ Scaler saved to: {scaler_path}")
            
            # Save label encoders
            encoders_path = os.path.join(output_dir, 'label_encoders.pkl')
            joblib.dump(self.label_encoders, encoders_path)
            print(f"  ‚úÖ Label encoders saved to: {encoders_path}")
            
            # Save training data info
            training_info_path = os.path.join(output_dir, 'training_info.pkl')
            joblib.dump(self.training_data_info, training_info_path)
            print(f"  ‚úÖ Training info saved to: {training_info_path}")
            
            # Save model metadata
            metadata = {
                'model_name': self.best_model_name,
                'feature_names': self.feature_names,
                'model_performance': self.training_data_info.get('model_performance', {}),
                'nei6_procedure_codes': self.nei6_procedure_codes,
                'creation_time': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            metadata_path = os.path.join(output_dir, 'model_metadata.json')
            import json
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            print(f"  ‚úÖ Model metadata saved to: {metadata_path}")
            
            print(f"  üéâ All model components saved successfully!")
            
        except Exception as e:
            print(f"  ‚ùå Error saving model: {str(e)}")
            import traceback
            traceback.print_exc()
    
    def load_model(self, model_dir):
        """Load a previously saved model"""
        print(f"üìÇ Loading model from: {model_dir}")
        
        try:
            # Load the model
            model_path = os.path.join(model_dir, 'trained_model.pkl')
            self.best_model = joblib.load(model_path)
            print(f"  ‚úÖ Model loaded from: {model_path}")
            
            # Load the scaler
            scaler_path = os.path.join(model_dir, 'scaler.pkl')
            self.scaler = joblib.load(scaler_path)
            print(f"  ‚úÖ Scaler loaded from: {scaler_path}")
            
            # Load label encoders
            encoders_path = os.path.join(model_dir, 'label_encoders.pkl')
            self.label_encoders = joblib.load(encoders_path)
            print(f"  ‚úÖ Label encoders loaded from: {encoders_path}")
            
            # Load training info
            training_info_path = os.path.join(model_dir, 'training_info.pkl')
            self.training_data_info = joblib.load(training_info_path)
            self.feature_names = self.training_data_info['feature_names']
            self.best_model_name = self.training_data_info['best_model_name']
            print(f"  ‚úÖ Training info loaded from: {training_info_path}")
            
            print(f"  üéâ Model loaded successfully!")
            return True
            
        except Exception as e:
            print(f"  ‚ùå Error loading model: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def predict_new_data(self, X_new):
        """Predict on new data using the loaded model"""
        if self.best_model is None:
            print("‚ùå No model loaded! Please load a model first.")
            return None
        
        try:
            # Ensure features are in the same order as training
            if isinstance(X_new, pd.DataFrame):
                X_new = X_new[self.feature_names]
            
            # Apply scaling
            X_new_scaled = self.scaler.transform(X_new)
            
            # Make predictions
            if self.best_model_name == 'LogisticRegression':
                predictions = self.best_model.predict(X_new_scaled)
                probabilities = self.best_model.predict_proba(X_new_scaled)[:, 1]
            else:
                predictions = self.best_model.predict(X_new)
                probabilities = self.best_model.predict_proba(X_new)[:, 1]
            
            return predictions, probabilities
            
        except Exception as e:
            print(f"‚ùå Error making predictions: {str(e)}")
            import traceback
            traceback.print_exc()
            return None, None
    
    def run_analysis_new_time(self, csv_file=None):
        """Run complete analysis with new time format"""
        print("üöÄ Starting TQIP new time format NEI-6 prediction analysis...")
        
        try:
            # 1. Load data
            df = self.load_data_from_csv(csv_file)
            
            # 2. Create NEI-6 labels from mapping
            df = self.create_nei6_labels_from_mapping(df)
            
            # 3. Prepare features
            X, y = self.prepare_features_new_time(df)
            if X is None:
                print("‚ùå Feature preparation failed!")
                return
            
            # 4. Train models
            best_result = self.train_models_new_time(X, y)
            
            # 5. Create output directory
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = f"tqip_nei6_new_time_results_{timestamp}"
            os.makedirs(output_dir, exist_ok=True)
            
            # 6. Create visualizations
            self.create_visualizations_new_time(best_result, output_dir)
            
            # 7. Generate report
            self.generate_report_new_time(best_result, output_dir)
            
            # 8. Save trained model
            self.save_model(output_dir)
            
            print(f"‚úÖ New time format NEI-6 prediction analysis completed! Results saved to: {output_dir}")
            
        except Exception as e:
            print(f"‚ùå Error occurred during analysis: {str(e)}")
            import traceback
            traceback.print_exc()

def demo_model_usage():
    """Demonstrate how to use the saved model for predictions"""
    print("üîÆ Model Usage Demo")
    print("=" * 40)
    
    # Create predictor
    predictor = TQIPNEI6LocalNewTimePredictor()
    
    # Find the most recent model directory
    import glob
    model_dirs = glob.glob("tqip_nei6_new_time_results_*")
    if not model_dirs:
        print("‚ùå No saved models found!")
        return
    
    latest_model_dir = max(model_dirs, key=os.path.getctime)
    print(f"üìÇ Loading latest model from: {latest_model_dir}")
    
    # Load the model
    if predictor.load_model(latest_model_dir):
        print("\nüéØ Model loaded successfully!")
        print(f"üìä Model type: {predictor.best_model_name}")
        print(f"üìä Features: {predictor.feature_names}")
        
        # Create sample prediction data
        print("\nüîÆ Making predictions on sample data...")
        sample_data = pd.DataFrame({
            'age': [35, 45, 25],
            'sex': [1, 2, 1],
            'total_gcs': [12, 8, 15],
            'sbp': [110, 90, 130],
            'evening_arrival': [0, 1, 0],
            'firearm_injury': [0, 1, 0],
            'fall_injury': [1, 0, 0],
            'unintentional_injury': [1, 0, 1],
            'central_gunshot_wound': [0, 1, 0]
        })
        
        predictions, probabilities = predictor.predict_new_data(sample_data)
        if predictions is not None:
            print("üìä Predictions:")
            for i, (pred, prob) in enumerate(zip(predictions, probabilities)):
                print(f"  Patient {i+1}: NEI-6 = {'Positive' if pred else 'Negative'} (Probability: {prob:.3f})")

def main():
    """Main function"""
    print("üè• TQIP New Time Format NEI-6 Prediction Model")
    print("=" * 60)
    
    # Create predictor
    predictor = TQIPNEI6LocalNewTimePredictor()
    
    # Run analysis with sample data
    sample_csv = "sample_tqip_local_features.csv"
    if os.path.exists(sample_csv):
        predictor.run_analysis_new_time(sample_csv)
        
        # Demonstrate model usage
        print("\n" + "="*60)
        demo_model_usage()
    else:
        print(f"‚ùå Sample CSV file not found: {sample_csv}")
        print("Please ensure the sample CSV file exists in the current directory.")

if __name__ == "__main__":
    main()
